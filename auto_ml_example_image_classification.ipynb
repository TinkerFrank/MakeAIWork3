{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Image Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import sklearn.model_selection\n",
        "\n",
        "import torchvision.datasets\n",
        "\n",
        "from autoPyTorch.pipeline.image_classification import ImageClassificationPipeline\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator1 = torch.Generator().manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the dataset path and transformation\n",
        "dataset_path = \"./Project 3/apple_resized_224/Train\"\n",
        "transform_img_normal = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "dataset = ImageFolder(dataset_path, transform=transform_img_normal)\n",
        "\n",
        "# split in train and test\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size],generator=generator1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract properties from the subset object\n",
        "dataset = train_dataset.dataset\n",
        "indices = train_dataset.indices\n",
        "\n",
        "# Create a dictionary with the extracted properties\n",
        "dataset_properties = {\n",
        "    'dataset': dataset,\n",
        "    'indices': indices\n",
        "}\n",
        "\n",
        "# Extract properties from the subset object\n",
        "testdataset = test_dataset.dataset\n",
        "testindices = test_dataset.indices\n",
        "\n",
        "# Create a dictionary with the extracted properties\n",
        "testdataset_properties = {\n",
        "    'dataset': testdataset,\n",
        "    'indices': testindices\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "________________________________________\n",
            "\tImageClassificationPipeline\n",
            "________________________________________\n",
            "0-) normalizer: \n",
            "\tImageNormalizer\n",
            "\n",
            "1-) preprocessing: \n",
            "\tEarlyPreprocessing\n",
            "\n",
            "2-) image_augmenter: \n",
            "\tImageAugmenter\n",
            "\n",
            "________________________________________\n"
          ]
        }
      ],
      "source": [
        "data = dataset_properties\n",
        "\n",
        "pipeline = ImageClassificationPipeline(dataset_properties=data)\n",
        "print(pipeline)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate mean and standard deviation\n",
        "mean = torch.stack([torch.mean(img, dim=0) for img, _ in train_dataset])\n",
        "std = torch.stack([torch.std(img, dim=0) for img, _ in train_dataset])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline CS:\n",
            " ________________________________________ \n",
            "Configuration space object:\n",
            "  Hyperparameters:\n",
            "    image_augmenter:GaussianBlur:sigma_min, Type: UniformFloat, Range: [0.0, 3.0], Default: 0.0\n",
            "    image_augmenter:GaussianBlur:sigma_offset, Type: UniformFloat, Range: [0.0, 3.0], Default: 0.5\n",
            "    image_augmenter:GaussianBlur:use_augmenter, Type: Categorical, Choices: {True, False}, Default: True\n",
            "    image_augmenter:GaussianNoise:sigma_offset, Type: UniformFloat, Range: [0.0, 3.0], Default: 0.3\n",
            "    image_augmenter:GaussianNoise:use_augmenter, Type: Categorical, Choices: {True, False}, Default: True\n",
            "    image_augmenter:RandomAffine:rotate, Type: UniformInteger, Range: [0, 360], Default: 45\n",
            "    image_augmenter:RandomAffine:scale_offset, Type: UniformFloat, Range: [0.0, 0.4], Default: 0.2\n",
            "    image_augmenter:RandomAffine:shear, Type: UniformInteger, Range: [0, 45], Default: 30\n",
            "    image_augmenter:RandomAffine:translate_percent_offset, Type: UniformFloat, Range: [0.0, 0.4], Default: 0.2\n",
            "    image_augmenter:RandomAffine:use_augmenter, Type: Categorical, Choices: {True, False}, Default: True\n",
            "    image_augmenter:RandomCutout:p, Type: UniformFloat, Range: [0.2, 1.0], Default: 0.5\n",
            "    image_augmenter:RandomCutout:use_augmenter, Type: Categorical, Choices: {True, False}, Default: True\n",
            "    image_augmenter:Resize:use_augmenter, Type: Categorical, Choices: {True, False}, Default: True\n",
            "    image_augmenter:ZeroPadAndCrop:percent, Type: UniformFloat, Range: [0.0, 0.5], Default: 0.1\n",
            "    normalizer:__choice__, Type: Categorical, Choices: {ImageNormalizer, NoNormalizer}, Default: ImageNormalizer\n",
            "  Conditions:\n",
            "    image_augmenter:GaussianBlur:sigma_min | image_augmenter:GaussianBlur:use_augmenter == True\n",
            "    image_augmenter:GaussianBlur:sigma_offset | image_augmenter:GaussianBlur:use_augmenter == True\n",
            "    image_augmenter:GaussianNoise:sigma_offset | image_augmenter:GaussianNoise:use_augmenter == True\n",
            "    image_augmenter:RandomAffine:rotate | image_augmenter:RandomAffine:use_augmenter == True\n",
            "    image_augmenter:RandomAffine:scale_offset | image_augmenter:RandomAffine:use_augmenter == True\n",
            "    image_augmenter:RandomAffine:shear | image_augmenter:RandomAffine:use_augmenter == True\n",
            "    image_augmenter:RandomAffine:translate_percent_offset | image_augmenter:RandomAffine:use_augmenter == True\n",
            "    image_augmenter:RandomCutout:p | image_augmenter:RandomCutout:use_augmenter == True\n",
            "\n",
            "Pipeline Random Config:\n",
            " ________________________________________ \n",
            "Configuration(values={\n",
            "  'image_augmenter:GaussianBlur:use_augmenter': False,\n",
            "  'image_augmenter:GaussianNoise:sigma_offset': 1.2628515533402975,\n",
            "  'image_augmenter:GaussianNoise:use_augmenter': True,\n",
            "  'image_augmenter:RandomAffine:use_augmenter': False,\n",
            "  'image_augmenter:RandomCutout:p': 0.9485118711649887,\n",
            "  'image_augmenter:RandomCutout:use_augmenter': True,\n",
            "  'image_augmenter:Resize:use_augmenter': True,\n",
            "  'image_augmenter:ZeroPadAndCrop:percent': 0.30442088360592373,\n",
            "  'normalizer:__choice__': 'NoNormalizer',\n",
            "})\n",
            "\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Expected X_train to be instance of (<class 'numpy.ndarray'>, <class 'pandas.core.frame.DataFrame'>, <class 'scipy.sparse._base.spmatrix'>) got <class 'torchvision.datasets.folder.ImageFolder'>",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 24\u001b[0m\n\u001b[0;32m      6\u001b[0m pipeline\u001b[39m.\u001b[39mset_hyperparameters(config)\n\u001b[0;32m      9\u001b[0m \u001b[39m# pipeline.fit(X=dict(X_train=data,\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m#                     is_small_preprocess=True,\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m#                     dataset_properties=dict(mean=mean.numpy(),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \n\u001b[0;32m     23\u001b[0m \u001b[39m# Fit the pipeline\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m pipeline\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(X_train\u001b[39m=\u001b[39;49mtrain_dataset\u001b[39m.\u001b[39;49mdataset ,\n\u001b[0;32m     25\u001b[0m              dataset_properties\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(\n\u001b[0;32m     26\u001b[0m                  mean\u001b[39m=\u001b[39;49mmean\u001b[39m.\u001b[39;49mnumpy(),\n\u001b[0;32m     27\u001b[0m                  std\u001b[39m=\u001b[39;49mstd\u001b[39m.\u001b[39;49mnumpy(),\n\u001b[0;32m     28\u001b[0m                  num_classes\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,\n\u001b[0;32m     29\u001b[0m                  num_features\u001b[39m=\u001b[39;49mdataset[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m] \u001b[39m*\u001b[39;49m dataset[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m],\n\u001b[0;32m     30\u001b[0m                  image_height\u001b[39m=\u001b[39;49mdataset[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m],\n\u001b[0;32m     31\u001b[0m                  image_width\u001b[39m=\u001b[39;49mdataset[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m],\n\u001b[0;32m     32\u001b[0m              ),\n\u001b[0;32m     33\u001b[0m              train_indices\u001b[39m=\u001b[39;49mdataset_properties[\u001b[39m'\u001b[39;49m\u001b[39mindices\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m     34\u001b[0m              val_indices\u001b[39m=\u001b[39;49mtestdataset_properties[\u001b[39m'\u001b[39;49m\u001b[39mindices\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     35\u001b[0m              )\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[39mprint\u001b[39m(pipeline)\n",
            "File \u001b[1;32md:\\0_Program_Files\\Python3.11\\Lib\\site-packages\\autoPyTorch\\pipeline\\base_pipeline.py:154\u001b[0m, in \u001b[0;36mBasePipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X: Dict[\u001b[39mstr\u001b[39m, Any], y: Optional[np\u001b[39m.\u001b[39mndarray] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    131\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Pipeline:\n\u001b[0;32m    132\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the selected algorithm to the training data.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \n\u001b[0;32m    134\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39m            a classification algorithm first.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m     X, fit_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_transformer(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_estimator(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    156\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[1;32md:\\0_Program_Files\\Python3.11\\Lib\\site-packages\\autoPyTorch\\pipeline\\base_pipeline.py:166\u001b[0m, in \u001b[0;36mBasePipeline.fit_transformer\u001b[1;34m(self, X, y, fit_params)\u001b[0m\n\u001b[0;32m    163\u001b[0m fit_params \u001b[39m=\u001b[39m {key\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m): value \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m\n\u001b[0;32m    164\u001b[0m               fit_params\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m    165\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 166\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[0;32m    167\u001b[0m \u001b[39mreturn\u001b[39;00m Xt, fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n",
            "File \u001b[1;32md:\\0_Program_Files\\Python3.11\\Lib\\site-packages\\sklearn\\pipeline.py:303\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    301\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    302\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 303\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    304\u001b[0m     cloned_transformer, X, y, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    305\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    306\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[0;32m    307\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name])\n\u001b[0;32m    308\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
            "File \u001b[1;32md:\\0_Program_Files\\Python3.11\\Lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32md:\\0_Program_Files\\Python3.11\\Lib\\site-packages\\sklearn\\pipeline.py:756\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    754\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    755\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 756\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    758\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    759\u001b[0m     \u001b[39mreturn\u001b[39;00m res, transformer\n",
            "File \u001b[1;32md:\\0_Program_Files\\Python3.11\\Lib\\site-packages\\autoPyTorch\\pipeline\\components\\base_choice.py:217\u001b[0m, in \u001b[0;36mautoPyTorchChoice.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitted_ \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchoice \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mCannot call fit without initializing the component\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 217\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchoice\u001b[39m.\u001b[39;49mfit(X, y)\n",
            "File \u001b[1;32md:\\0_Program_Files\\Python3.11\\Lib\\site-packages\\autoPyTorch\\pipeline\\components\\preprocessing\\image_preprocessing\\normalise\\NoNormalizer.py:28\u001b[0m, in \u001b[0;36mNoNormalizer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X: Dict[\u001b[39mstr\u001b[39m, Any], y: Optional[Any] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNoNormalizer\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     20\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m    Initialises early_preprocessor and returns self.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39m        autoPyTorchImagePreprocessingComponent: self\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_requirements(X, y)\n\u001b[0;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[1;32md:\\0_Program_Files\\Python3.11\\Lib\\site-packages\\autoPyTorch\\pipeline\\components\\preprocessing\\image_preprocessing\\normalise\\base_normalizer.py:34\u001b[0m, in \u001b[0;36mBaseNormalizer.check_requirements\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_requirements\u001b[39m(\u001b[39mself\u001b[39m, X: Dict[\u001b[39mstr\u001b[39m, Any], y: Any \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39m    A mechanism in code to ensure the correctness of the fit dictionary\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39m    It recursively makes sure that the children and parent level requirements\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39m            so that further stages can be properly fitted\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcheck_requirements(X, y)\n\u001b[0;32m     36\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39min\u001b[39;00m X[\u001b[39m'\u001b[39m\u001b[39mdataset_properties\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mstd\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     37\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mZeroDivisionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt normalise when std is zero\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32md:\\0_Program_Files\\Python3.11\\Lib\\site-packages\\autoPyTorch\\pipeline\\components\\base_component.py:277\u001b[0m, in \u001b[0;36mautoPyTorchComponent.check_requirements\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    275\u001b[0m TYPE_SUPPORTED \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(check_dict[requirement\u001b[39m.\u001b[39mname], \u001b[39mtuple\u001b[39m(requirement\u001b[39m.\u001b[39msupported_types))\n\u001b[0;32m    276\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m TYPE_SUPPORTED:\n\u001b[1;32m--> 277\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to be instance of \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                     \u001b[39m.\u001b[39mformat(requirement\u001b[39m.\u001b[39mname,\n\u001b[0;32m    279\u001b[0m                             requirement\u001b[39m.\u001b[39msupported_types,\n\u001b[0;32m    280\u001b[0m                             \u001b[39mtype\u001b[39m(check_dict[requirement\u001b[39m.\u001b[39mname])))\n",
            "\u001b[1;31mTypeError\u001b[0m: Expected X_train to be instance of (<class 'numpy.ndarray'>, <class 'pandas.core.frame.DataFrame'>, <class 'scipy.sparse._base.spmatrix'>) got <class 'torchvision.datasets.folder.ImageFolder'>"
          ]
        }
      ],
      "source": [
        "# Configuration space\n",
        "pipeline_cs = pipeline.get_hyperparameter_search_space()\n",
        "print(\"Pipeline CS:\\n\", '_' * 40, f\"\\n{pipeline_cs}\")\n",
        "config = pipeline_cs.sample_configuration()\n",
        "print(\"Pipeline Random Config:\\n\", '_' * 40, f\"\\n{config}\")\n",
        "pipeline.set_hyperparameters(config)\n",
        "\n",
        "\n",
        "# pipeline.fit(X=dict(X_train=data,\n",
        "#                     is_small_preprocess=True,\n",
        "#                     dataset_properties=dict(mean=mean.numpy(),\n",
        "#                                             std=std.numpy(),\n",
        "#                                             num_classes=4,\n",
        "#                                             num_features=dataset[0][0].shape[0] * dataset[0][0].shape[1],\n",
        "#                                             image_height=dataset[0][0].shape[1],\n",
        "#                                             image_width=dataset[0][0].shape[2],\n",
        "#                                             is_small_preprocess=True),\n",
        "#                     train_indices=dataset_properties['indices'],\n",
        "#                     val_indices=testdataset_properties['indices']\n",
        "#                     )\n",
        "#              )\n",
        "    \n",
        "# Fit the pipeline\n",
        "pipeline.fit(X=dict(X_train=train_dataset.dataset ,\n",
        "             dataset_properties=dict(\n",
        "                 mean=mean.numpy(),\n",
        "                 std=std.numpy(),\n",
        "                 num_classes=4,\n",
        "                 num_features=dataset[0][0].shape[0] * dataset[0][0].shape[1],\n",
        "                 image_height=dataset[0][0].shape[1],\n",
        "                 image_width=dataset[0][0].shape[2],\n",
        "             ),\n",
        "             train_indices=dataset_properties['indices'],\n",
        "             val_indices=testdataset_properties['indices']\n",
        "             )\n",
        ")\n",
        "print(pipeline)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
